{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/worldbank/dec-python-course/blob/main/1-foundations/3-numpy-and-pandas/foundations-s3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Python for Data Science - Session 3\n",
        "\n",
        "This session first talks about python libraries – what are they and how to use them. Then it focuses on two libraries that are very commonly used in data science, NumPy and Pandas, with examples on data exploration and wrangling."
      ],
      "metadata": {
        "id": "o1N3qhyA0T3w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.Python Libraries\n",
        "\n",
        "Within the realm of python, a package is a collection of modules, a library is a collection of packages. In practice, \"python library\" and \"python package\" are used interchangeably to refer to a reusable chunk of code. Use of libraries allows us to \"stand on the shoulders of giants\"."
      ],
      "metadata": {
        "id": "nGwJPbjEc44k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1. Examples of Python libraries\n",
        "- [NumPy](https://numpy.org/) stands for Numerical Python. It is the fundamental Python package for scientific computing.\n",
        "- [pandas](https://pandas.pydata.org/) is a Python package for fast and efficient processing of tabular data, time series, matrix data, etc.\n",
        "- [Matplotlib](https://matplotlib.org/)  is a comprehensive library for creating data visualizations in Python."
      ],
      "metadata": {
        "id": "Z_z4OH2Cw165"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2. How to use libraries?"
      ],
      "metadata": {
        "id": "d-1OvfSZ2e5m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNtSS8HZeIV5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(np.pi)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`import` followed by the library name loads the library into the environment. `as` is optional; it is usually used to alias the library name to a shorthand or for disambiguation. The above are some conventional aliases for these libraries. If you `import numpy` without aliasing, just be sure to use `numpy` instead of `np` when calling the library's functions later.\n",
        "\n",
        "`import` the library like you would import a built-in python module works for common libraries on most cloud-based python notebook environments (e.g. Google Colab and Databricks) because they already pre-installed many common libraries like Pandas and NumPy."
      ],
      "metadata": {
        "id": "Y6CkPZNx20Lq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3. What libraries are pre-installed?\n",
        "\n",
        "[pip](https://pip.pypa.io/) is the de facto python package manager. You can use it to view the current installed packages:"
      ],
      "metadata": {
        "id": "YrdT4xNYdqZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: ! in a notebook environment executes a bash command\n",
        "# `| head` shortens the output to show only the first 10\n",
        "!pip freeze | head"
      ],
      "metadata": {
        "id": "CBYYko-23YKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To check if a library you want to use is already installed:"
      ],
      "metadata": {
        "id": "CBMqUBUi3qfl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# `| grep` filters the output using the supplied keyword\n",
        "!pip freeze | grep pandas"
      ],
      "metadata": {
        "id": "7dNMg6iX3wIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bash commands are commonly referred to as the terminal, console or command line. It's an interface to interact with a Unix-based operating system, which the notebook environment runs on. For the purpose of this session, we just need to know commands that start with `!` are bash commands, not python code. `grep`, `head`, `pip` are bash commands. `|` is known as the pipe, which channels the output of one bash command to another as the input. We use these bash commands to install, update, and view python packages."
      ],
      "metadata": {
        "id": "Uc6vxBS06gm_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.4. Can I install a new library?\n",
        "\n",
        "Again, we use the package manager `pip` to install a new package:"
      ],
      "metadata": {
        "id": "-eZ2_CmN4Mzq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install package wbgapi, for programmatically access the World Bank's data API\n",
        "!pip install wbgapi"
      ],
      "metadata": {
        "id": "jiOOOA9w4UeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5 How do I get help using a library?\n",
        "\n",
        "Ask Google or ChatGPT, or directly reference the library's documentation:\n",
        "\n",
        "- Pandas documentation: https://pandas.pydata.org/docs/reference/frame.html\n",
        "- NumPy documentation: https://numpy.org/doc/stable/reference/arrays.ndarray.html\n",
        "\n",
        "Inside a notebook environment, you can always invoke `help()` to bring up the documentation for any function:"
      ],
      "metadata": {
        "id": "kzycubXAOqiK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "help(pd.isna)"
      ],
      "metadata": {
        "id": "KHsjXa3gQSbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.NumPy\n",
        "\n",
        "NumPy (**Numerical Python**) is an open source Python library that’s used in almost every field of science and engineering. It’s the **universal standard** for working with numerical data in Python, and it’s at the core of the scientific Python and PyData ecosystems. It serves as the foundation for popular data science and scientific Python packages, such as Pandas, SciPy, Matplotlib, scikit-learn.\n",
        "\n",
        "This section is only covered in a full-day session, and left for self study for a half-day session. See [foundations-s3-numpy.ipynb](https://github.com/worldbank/dec-python-course/blob/main/1-foundations/3-numpy-and-pandas/foundations-s3-numpy.ipynb) for the corresponding material.\n"
      ],
      "metadata": {
        "id": "Vy-R-M5N2I6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.Pandas\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/1400/1*6d5dw6dPhy4vBp2vRW6uzw.png\" width=800 />\n",
        "\n",
        "Image credit: https://towardsdatascience.com/pandas-groupby-aggregate-transform-filter-c95ba3444bbb"
      ],
      "metadata": {
        "id": "oQbrnlL81xm7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Datasets we often work with come in tabular form – think Excel/Google spreadsheets – and with mixed data types, some numerical, some categorical, some textual. Before we can perform fancy mathematical operations and meaningful analysis on such data using NumPy and other python libraries, we usually need to understand and preprocess the data first. This process involves operations such as cleaning, reshaping, filtering, and subsetting. This is where Pandas comes in.\n",
        "\n",
        "Aside: Why is such a data analysis library named Pandas? Apparently the name is derived from the term \"panel data\".\n",
        "\n",
        "Like `ndarray` is the basic building block of NumPy, `Series` and `DataFrame` are the basic building blocks of Pandas."
      ],
      "metadata": {
        "id": "apd7GljeDz59"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1. Series\n",
        "\n",
        "`Series` is a one-dimensional **labeled** array capable of holding **any data type**. The axis labels are collectively referred to as the index."
      ],
      "metadata": {
        "id": "DSpeS492gLEW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Can I create a Series from a list?"
      ],
      "metadata": {
        "id": "ec5MCn0bg-EP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# specify the labels through the `index` argument\n",
        "labelled_series = pd.Series([1, 2, 3], index=[\"r1\", \"r2\", \"r3\"])\n",
        "labelled_series"
      ],
      "metadata": {
        "id": "ZIWcxaKfhanx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# by default, integer sequence starting from 0 is used as labels\n",
        "default_series = pd.Series([1, 2, 3])\n",
        "default_series"
      ],
      "metadata": {
        "id": "bbbahkW1h2Fg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Individual elements can be looked up using labels\n",
        "labelled_series[\"r2\"]"
      ],
      "metadata": {
        "id": "15h1ZumAip1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "default_series[2]"
      ],
      "metadata": {
        "id": "peq4eUTujAI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Can I recover the list from a series?"
      ],
      "metadata": {
        "id": "c8oV6eavh0Wx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labelled_series.to_list()"
      ],
      "metadata": {
        "id": "ZEK4BJCTh0W7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Can I create a Series from an ndarray?"
      ],
      "metadata": {
        "id": "-9n5RgsFhWe8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# specify the labels through the `index` argument\n",
        "labelled_series = pd.Series(np.arange(1, 4), index=[\"r1\", \"r2\", \"r3\"])\n",
        "labelled_series"
      ],
      "metadata": {
        "id": "HzRJcCqKhWfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# by default, integer sequence starting from 0 is used as labels\n",
        "default_series = pd.Series(np.arange(1, 4))\n",
        "default_series"
      ],
      "metadata": {
        "id": "MeYlloAhhWfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Individual elements can be looked up using labels\n",
        "labelled_series[\"r2\"]"
      ],
      "metadata": {
        "id": "gMgdvS45hWfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "default_series[2]"
      ],
      "metadata": {
        "id": "fvoV8-9chWfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Can I recover the ndarray from a series?"
      ],
      "metadata": {
        "id": "7Ne5U5vdjxPU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labelled_series.to_numpy()"
      ],
      "metadata": {
        "id": "PtYrA1CSjrJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# alternatively\n",
        "labelled_series.values"
      ],
      "metadata": {
        "id": "kF-8b0AloO1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Can I apply the same transformation on every element in a Series?"
      ],
      "metadata": {
        "id": "JXyQLgt9QN_k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's similar to iterating through a list with a `for` or `while` loop, but in tabular data, the mindset is to apply the same `function` on every element in a Series. Why the change of mindset? The short answer is that it allows the library to perform the operations faster through parallel processing. For technical details, refer to [this blog post](https://medium.com/analytics-vidhya/understanding-vectorization-in-numpy-and-pandas-188b6ebc5398) (which also links to a talk specifically on such optimization approach known as vectorization)."
      ],
      "metadata": {
        "id": "6Xq2orxrSiPw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's an example of transforming a list of strings to UPPERCASE using a `for` loop:"
      ],
      "metadata": {
        "id": "Jw_ky9xRVr_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "angry_libs = []\n",
        "for lib in ['numpy', 'pandas']:\n",
        "  angry_libs.append(lib.upper())\n",
        "angry_libs"
      ],
      "metadata": {
        "id": "H0GnbR6KRZoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's how we would do it on a Series:"
      ],
      "metadata": {
        "id": "6xzoPyOnWSNk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Series(['numpy', 'pandas']).map(str.upper)"
      ],
      "metadata": {
        "id": "JvjKpY1VWWUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's break it down:"
      ],
      "metadata": {
        "id": "mm2m0HREWa6l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "libraries = pd.Series(['numpy', 'pandas'])\n",
        "libraries"
      ],
      "metadata": {
        "id": "nAS5-WipQhiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "str.upper"
      ],
      "metadata": {
        "id": "SayhuzJyRNd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "libraries.map(str.upper)"
      ],
      "metadata": {
        "id": "12wbWIQfRBj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2. DataFrame\n",
        "\n",
        "`DataFrame` is a 2-dimensional **labeled** data structure with **columns of potentially different types**. You can think of it like a spreadsheet or SQL table, or a dict of Series objects. It is generally the most commonly used pandas object."
      ],
      "metadata": {
        "id": "Yj-JuBEuhhvG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.1. Creating DataFrames\n",
        "\n",
        "There are many ways to create a `DataFrame`. Let's look at some examples with the data types we are already familiar with."
      ],
      "metadata": {
        "id": "wCQIFZbgLKTl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Can I create a DataFrame from Series?"
      ],
      "metadata": {
        "id": "kec7XEzdiTC5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_from_series = pd.DataFrame({\"c1\": labelled_series, \"c2\": labelled_series * 2})\n",
        "df_from_series"
      ],
      "metadata": {
        "id": "QcAkiwxGib61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_from_series.columns"
      ],
      "metadata": {
        "id": "NOQ_nHiSkukP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_from_series.index"
      ],
      "metadata": {
        "id": "NFENQGSSlm8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Can I create a DataFrame from an ndarray?"
      ],
      "metadata": {
        "id": "tOnURc2ylued"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_values = np.arange(1, 7).reshape(2, -1)\n",
        "raw_values"
      ],
      "metadata": {
        "id": "QDDv3JfVmGKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_from_ndarray = pd.DataFrame(raw_values, columns=['A', 'B', 'C'])\n",
        "df_from_ndarray"
      ],
      "metadata": {
        "id": "9jAZaBOJloiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To recover the raw values from a `DataFrame`:"
      ],
      "metadata": {
        "id": "uK3s5dmuon7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_from_ndarray.values"
      ],
      "metadata": {
        "id": "pYlo3Ec7oCzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Can I create a DataFrame from lists?"
      ],
      "metadata": {
        "id": "LKZJgFi9m1kL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame({\"ID\": [1, 2], \"Name\": [\"dog\", \"cat\"], \"Needs Walking\": [True, False]})"
      ],
      "metadata": {
        "id": "8E02RfDEm6h3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Can I create a DataFrame from a file?"
      ],
      "metadata": {
        "id": "urMFL5Q3pDsW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_url = 'https://raw.githubusercontent.com/worldbank/dec-python-course/main/1-foundations/3-numpy-and-pandas/data/Singapore_Annual_New_Car_Registrations_by_make_type.csv'\n",
        "singapore_cars = pd.read_csv(file_url)\n",
        "singapore_cars"
      ],
      "metadata": {
        "id": "_ZPpStkhpbZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To save a `DataFrame` as a csv file:"
      ],
      "metadata": {
        "id": "fB1MkhQ4vBqt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "singapore_cars.to_csv('singapore_cars.csv')"
      ],
      "metadata": {
        "id": "VKPBAO7At7hB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Colab, navigate to the folder icon in the left pane to find and download the exported csv file.\n",
        "\n",
        "In Databricks, invoke `display(singapore_cars)` then click on the \\\\( \\vee \\\\) icon next to the download icon under the output data grid, select \"Download all rows\"."
      ],
      "metadata": {
        "id": "NF6ESucbv3sQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(singapore_cars)"
      ],
      "metadata": {
        "id": "9o7uCAW2Ek7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.2. Inspecting the data\n",
        "\n",
        "Now let's perform some basic inspection to understand our dataset."
      ],
      "metadata": {
        "id": "jPPh4jhhw2uR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### How many rows and columns?"
      ],
      "metadata": {
        "id": "Lkl2tIOzxmVE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "singapore_cars.shape"
      ],
      "metadata": {
        "id": "A_skn1V2xH2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nrow, ncol = singapore_cars.shape\n",
        "print(f'nrow={nrow}, ncol={ncol}')"
      ],
      "metadata": {
        "id": "6NNO7EXXzptW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What are the column names?"
      ],
      "metadata": {
        "id": "4P7htLGvxs7N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "singapore_cars.columns"
      ],
      "metadata": {
        "id": "kzHsABg4xKwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What does the data look like?\n",
        "\n",
        "From the top:"
      ],
      "metadata": {
        "id": "XXxyBZVoyE16"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "singapore_cars.head()"
      ],
      "metadata": {
        "id": "WsU42CC8yKTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the bottom:"
      ],
      "metadata": {
        "id": "52ELu1E5x0GV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Optionally specify the exact number of rows you want\n",
        "singapore_cars.tail(3)"
      ],
      "metadata": {
        "id": "_QaUtw33ySXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What type of data does each column currently hold and how many missing values?\n"
      ],
      "metadata": {
        "id": "7dII_PI_y9uU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "singapore_cars.info()"
      ],
      "metadata": {
        "id": "7vSbYN4zyXvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.3. Subsetting the data\n",
        "\n",
        "A crucial part of working with DataFrames is extracting subsets of the data: finding rows that meet a certain set of criteria, isolating columns/rows of interest, etc. After narrowing down our data, we are closer to discovering insights. This section will be the backbone of many analysis tasks."
      ],
      "metadata": {
        "id": "XHvC3_UM0kH8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### How to select columns?\n",
        "\n",
        "To select a single column (returns a `Series`):"
      ],
      "metadata": {
        "id": "gbJLFEtS03Mh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "singapore_cars.make"
      ],
      "metadata": {
        "id": "Gz12xGUS0sSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Alternatively\n",
        "singapore_cars['make']"
      ],
      "metadata": {
        "id": "aiZUCXXh1B1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dictionary accessor is useful when the column name is not a valid Python variable, or when selecting multiple columns:"
      ],
      "metadata": {
        "id": "YcoiVUxz1GG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "singapore_cars[['make', 'fuel', 'type']]"
      ],
      "metadata": {
        "id": "fb6HCo5R1Er_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### How to select rows?\n",
        "If the index are default sequential integers, simply select as if you are selecting from an array:"
      ],
      "metadata": {
        "id": "UDu0HRs-1-NV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "singapore_cars[100:200]"
      ],
      "metadata": {
        "id": "kpkNuTfx2bP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### How to select by columns and rows (aka indexing)?\n",
        "\n",
        "Sometimes we want a specific \"section\" of the `DataFrame`, say the first 3 rows with just the middle 3 columns:"
      ],
      "metadata": {
        "id": "8TDILsqY2se5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "singapore_cars.iloc[0:3, 1:4]"
      ],
      "metadata": {
        "id": "QYw4X9dB3Nxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note** that it's not `()` that follows `iloc` but `[]`. This is because `iloc` is not a function/method, but a property on the DataFrame object.\n",
        "\n",
        "We use `iloc` to select by row and column's positions above; use `loc` to select by row and column's names/labels:"
      ],
      "metadata": {
        "id": "BS7B-O2k3zMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "singapore_cars.loc[10:15, ['year', 'number']]"
      ],
      "metadata": {
        "id": "p_GIlYlo4F09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case the rows' positions happen to be the same as the rows' names/labels.\n",
        "\n",
        "**Important**: when selecting by position (`iloc`) only the start point is included, the end point is excluded. When selecting by name/label (`loc`), both start and end points are included."
      ],
      "metadata": {
        "id": "76go0Hh04ni1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### How to filter rows based on conditions?\n",
        "\n",
        "This is useful when we want to zoom in to explore a subset of the data satisfying some condition(s). For example, to get only 2021 data on petrol cars:"
      ],
      "metadata": {
        "id": "Vx2ljK5B5EDz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "singapore_cars[(singapore_cars.year == 2021) & (singapore_cars.fuel == 'Petrol')]"
      ],
      "metadata": {
        "id": "a7V6Nszb5_H2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Important**: Take note of the syntax here. We surround each condition with parentheses, and we use bitwise operators (`&`, `|`, `~`) instead of logical operators (`and`, `or`, `not`)."
      ],
      "metadata": {
        "id": "EN8IUoAH6bbj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This mode of row selection/filtering is called \"boolean indexing\" because the selection is based on the specified condition evaluating to `True` or `False` (aka boolean). Rows that satisfy the condition are selected; those do not are filtered out. You can see the condition for the above example gets evaluated for each row as `True`/`False`:"
      ],
      "metadata": {
        "id": "yb0JINE69DV5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(singapore_cars.year == 2021) & (singapore_cars.fuel == 'Petrol')"
      ],
      "metadata": {
        "id": "GO6bHj8i-IBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Think of `True` as 1 and `False` as 0, summing along the resulting `Series` gives us the number of rows that satisfy our condition, which matches our boolean indexing results above:"
      ],
      "metadata": {
        "id": "l-NiTFad-gye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sum((singapore_cars.year == 2021) & (singapore_cars.fuel == 'Petrol'))"
      ],
      "metadata": {
        "id": "_7fGhwBR-I10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combining boolean indexing and `loc` allows us to conditionally replace values in a dataframe:"
      ],
      "metadata": {
        "id": "Nceymxx1tm4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "singapore_cars.loc[singapore_cars.fuel == 'Petrol', \"fuel\"] = 'Gasoline'\n",
        "singapore_cars"
      ],
      "metadata": {
        "id": "8aqNoP1Yt3W6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.4. Exploring the data\n",
        "\n",
        "Exploratory analysis is crucial in understanding the data. Pandas provides functions such as `value_counts`, `nunique`, `describe` alongside common summary statistical functions including `max`, `min`, `mean`, `median` to help us with the process."
      ],
      "metadata": {
        "id": "JW-7uOl_ATPX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, recall the `number` column has many missing values, which means those records do not correspond to any registration:"
      ],
      "metadata": {
        "id": "bTUSgNkHB_F-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "singapore_cars.info()"
      ],
      "metadata": {
        "id": "fXP-Ee5hki74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's filter them out using boolean indexing:"
      ],
      "metadata": {
        "id": "j38BPaURkyxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "singapore_cars_cleaned = singapore_cars[~np.isnan(singapore_cars.number)]\n",
        "singapore_cars_cleaned.info()"
      ],
      "metadata": {
        "id": "dNV39fTjCb4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note the use of NumPy's universal function `np.isnan` on the numbers column (which is a Series). Boolean indexing just needs each row to evaluate to `True` or `False`, so any NumPy or Pandas function that operates on a Series and returns another Series of boolean can be used. This will be useful to keep in mind for the exercises coming right up!"
      ],
      "metadata": {
        "id": "4HjDRtRbfU0S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### How many unique rows?"
      ],
      "metadata": {
        "id": "f9vxgM-clCL6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "How many different types and makes of cars are registered in Singapore over time?"
      ],
      "metadata": {
        "id": "7fqlzLDWBD73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "singapore_cars_cleaned.year.value_counts()"
      ],
      "metadata": {
        "id": "_26w9sY3AeyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seems like the number of different types and makes of cars registered in Signapore are fairly constant over time. Just to be sure, we can check the breakdown in percentage:"
      ],
      "metadata": {
        "id": "NgjTlCXqFWWK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "singapore_cars_cleaned.year.value_counts(normalize=True)"
      ],
      "metadata": {
        "id": "Hhp53UqHFjc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's drill down to the 2021 registration data:"
      ],
      "metadata": {
        "id": "Nj1QZpkiBfaw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "singapore_cars_2021 = singapore_cars_cleaned[singapore_cars_cleaned.year == 2021]\n",
        "singapore_cars_2021"
      ],
      "metadata": {
        "id": "c_P1yolRBWx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What are the unique makes registered in 2021?"
      ],
      "metadata": {
        "id": "SmJbUQurGyzu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "singapore_cars_2021.make.unique()"
      ],
      "metadata": {
        "id": "PbZV-jnqGjyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How many unique values are there?"
      ],
      "metadata": {
        "id": "hAUNjbzFG2S1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "singapore_cars_2021.make.nunique()"
      ],
      "metadata": {
        "id": "rZtRZ94MG381"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### How to calculate summary statistics?"
      ],
      "metadata": {
        "id": "pBItKOiwlbCK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can find basic statistics like we did on an `ndarray`, for example, finding the maximum number of cars registered in 2021 by make, fuel and type:"
      ],
      "metadata": {
        "id": "Hb9dHqy9DTwi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "singapore_cars_2021.number.max()"
      ],
      "metadata": {
        "id": "QC24lMg6Ebid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is this most popular car (make-fule-type)?"
      ],
      "metadata": {
        "id": "t2a11vrPGRkR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "singapore_cars_2021.iloc[singapore_cars_2021.number.argmax(), ]"
      ],
      "metadata": {
        "id": "dttz4heeEpk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Going back to the all-time cleaned dataset, to quickly get common summary statistics for all columns at once:"
      ],
      "metadata": {
        "id": "bUPQK40fJQKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "singapore_cars_cleaned.describe(include='all')"
      ],
      "metadata": {
        "id": "hi4xCBeTHO77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Important**: NaN values signify missing data. For instance, the categorical/string columns such as `make`, `fuel` have no value for `mean`, `std` etc; likewise, numeric columns such as `number` and `year` have no entries for the categorical summary statistics (`unique`, `top`, `freq`)."
      ],
      "metadata": {
        "id": "YDNOcNa1JXQV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice often the output of a Pandas function is also a Pandas object, e.g. Series or DataFrame, or a NumPy ndarray. This means other Pandas/NumPy functions can also be applied on them. We will see some examples of chained operations in the following sections."
      ],
      "metadata": {
        "id": "jktryez30EC3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.5. Exercises: read and explore excel data"
      ],
      "metadata": {
        "id": "3jdkE99YhJtM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 1.\n",
        "\n",
        "Create a `DataFrame` by reading in the excel file from the given URL stored in the `exercise_data_url` variable. There are 3 sheets in the excel file, we only want the last sheet.\n",
        "\n",
        "Store the resulting DataFrame in a variable named `sg_cars_excel`:\n"
      ],
      "metadata": {
        "id": "r3CI3OznhORw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%script echo Remove this line after filling in your own code\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "exercise_data_url = 'https://raw.githubusercontent.com/worldbank/dec-python-course/main/1-foundations/3-numpy-and-pandas/data/Singapore_Annual_New_Car_Registrations_by_make_type.xls'\n",
        "\n",
        "# hint: use pd.read_excel, note sheet index starts with 0\n",
        "# Your code here\n",
        "\n",
        "assert sg_cars_excel.shape == (79, 12)"
      ],
      "metadata": {
        "id": "p49zDWEUkVIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 2.\n",
        "\n",
        "Inspect the first 3 and last 5 rows of `sg_cars_excel`:"
      ],
      "metadata": {
        "id": "C0gpmDMRnuRe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%script echo Remove this line after filling in your own code\n",
        "\n",
        "# hint: use head\n",
        "# Your code here"
      ],
      "metadata": {
        "id": "abugBJLdn-eJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%script echo Remove this line after filling in your own code\n",
        "\n",
        "# hint: use tail\n",
        "# Your code here"
      ],
      "metadata": {
        "id": "MgPOYYtspVRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 3.\n",
        "\n",
        "Notice the first value row in `sg_cars_excel` is in fact the years and should be used as the column names. The DataFrame also contains 3 footer rows we want to exclude. Fix it by re-reading the excel file with additional parameters.\n",
        "\n",
        "Store the fixed DataFrame in `sg_cars_excel_fixed`:"
      ],
      "metadata": {
        "id": "-9oandV8oQQi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%script echo Remove this line after filling in your own code\n",
        "\n",
        "# hint: check out pd.read_excel's arguments: header=, skipfooter=\n",
        "# Your code here\n",
        "\n",
        "assert sg_cars_excel_fixed.columns[1] == 2011\n",
        "assert sg_cars_excel_fixed.Make.iloc[0] == 'Alfa Romeo'\n",
        "assert sg_cars_excel_fixed.columns[-1] == 2021\n",
        "assert sg_cars_excel_fixed.Make.iloc[-1] == 'Others'\n",
        "assert sg_cars_excel_fixed.shape == (75, 12)"
      ],
      "metadata": {
        "id": "Mw2v9YIwpzB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 4.\n",
        "\n",
        "Inspect the summary statistics for every year in `sg_cars_excel_fixed`:"
      ],
      "metadata": {
        "id": "e6uAhtNWrv8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%script echo Remove this line after filling in your own code\n",
        "\n",
        "# hint: use describe\n",
        "# Your code here"
      ],
      "metadata": {
        "id": "O0OKRAaErhsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 5.\n",
        "\n",
        "Within the dataframe `sg_cars_excel_fixed`, isolate the annual numbers of new car registrations for the following 3 makes: \"Mercedes Benz\", \"Toyota\", \"Kia\" for all years. Store the resulting DataFrame in variable `sg_cars_excel_subset`:"
      ],
      "metadata": {
        "id": "453cyxxks7cn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%script echo Remove this line after filling in your own code\n",
        "\n",
        "# hint: use boolean indexing with .isin function on the make column\n",
        "#       You can run pd.Series.isin? to find documentation and usage examples\n",
        "# Your code here\n",
        "\n",
        "assert sg_cars_excel_subset.shape == (3, 12)\n",
        "assert \"Mercedes Benz\" in sg_cars_excel_subset.Make.values\n",
        "assert \"Toyota\" in sg_cars_excel_subset.Make.values\n",
        "assert \"Kia\" in sg_cars_excel_subset.Make.values"
      ],
      "metadata": {
        "id": "P4Y0uSoBtafi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 6.\n",
        "\n",
        "Only select the `Make` column and year 2019, 2020, and 2021 from the `sg_cars_excel_subset` DataFrame.\n",
        "\n",
        "Store the result in variable `sg_cars_excel_subsubset`:"
      ],
      "metadata": {
        "id": "INOrPAycuvLJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%script echo Remove this line after filling in your own code\n",
        "\n",
        "# hint: use column selection\n",
        "# Your code here\n",
        "\n",
        "assert sg_cars_excel_subsubset.shape == (3, 4)\n",
        "assert sg_cars_excel_subsubset.columns.to_list() == ['Make', 2019, 2020, 2021]"
      ],
      "metadata": {
        "id": "VTGMBzwdvJ56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3. Data Wrangling\n",
        "\n",
        "All that we have learned so far gives us some basic understand of data. Next let's find out how to perform data wrangling, including data cleaning, grouping, reshaping, merging and concatenation using Pandas."
      ],
      "metadata": {
        "id": "VInfxOuHfuCK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3.1. Data Cleaning\n",
        "\n",
        "In this section, we will take a look at dropping missing values; creating, renaming, and dropping columns; type conversion; and sorting – all of which make our analysis easier. We will be working with the Singapore monthly new car registration data – a dataset similar to the annual car registration data we worked previously, just more granular."
      ],
      "metadata": {
        "id": "ahIn81CpIQWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "cars_monthly = pd.read_csv('https://raw.githubusercontent.com/worldbank/dec-python-course/main/1-foundations/3-numpy-and-pandas/data/Singapore_Monthly_New_Car_Registrations_by_make_type.csv')\n",
        "cars_monthly"
      ],
      "metadata": {
        "id": "_r10Q0ouI812"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cars_monthly.info()"
      ],
      "metadata": {
        "id": "5E0-Nn_tM5_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Handling missing values**"
      ],
      "metadata": {
        "id": "PD8HRVXNPAN9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are multiple approaches to handle missing values – see [Pandas' user guide on working with missing data](https://pandas.pydata.org/docs/user_guide/missing_data.html) for more details. In our case let's drop the rows with missing values for the `number` column, as those records indicate there is no corresponding car registration for that month, make, fuel and vehicle type:"
      ],
      "metadata": {
        "id": "hCbDeUmTLZS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cars_monthly.dropna(subset=['number'])"
      ],
      "metadata": {
        "id": "rvoY0SvKLyt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The argument `subset` here indicates which columns to evaluate for `na` values. If not specified, by default `dropna` will drop any row with any column containing `na` values.\n",
        "\n",
        "The call to `dropna` by default also does not modify the original `DataFrame`; it returns a new `DataFrame` with `na` values dropped."
      ],
      "metadata": {
        "id": "OOfh8YhJMVZi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cars_monthly.shape"
      ],
      "metadata": {
        "id": "87JSfwatN_WC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can assign the returned `DataFrame` to a new variable, or we can tell `dropna` to modify the original `DataFrame` by passing the `inplace=True` parameter:"
      ],
      "metadata": {
        "id": "CCI6ObroN5Bu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cars_monthly.dropna(subset=['number'], inplace=True)\n",
        "cars_monthly.shape"
      ],
      "metadata": {
        "id": "oDmvgKXwNp2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Renaming columns**\n",
        "\n",
        "Let's rename the `month` column to `year_month`:"
      ],
      "metadata": {
        "id": "B-ZJQz7rPtsx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cars_monthly_renamed = cars_monthly.rename(columns={'month': 'year_month'})\n",
        "cars_monthly_renamed.columns"
      ],
      "metadata": {
        "id": "Pk2h8s0JP4-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Creating columns**\n",
        "\n",
        "Let's create separate columns for year and month from the `year_month` column:"
      ],
      "metadata": {
        "id": "1hhbQAM-PHzR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cars_monthly_renamed[['year','month']] = cars_monthly_renamed.year_month.str.split(\"-\", expand=True)\n",
        "cars_monthly_renamed"
      ],
      "metadata": {
        "id": "XoTk4gEiQSFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Dropping columns**\n",
        "\n",
        "Now we can drop the redundant `year_month` column:"
      ],
      "metadata": {
        "id": "0iTaoEzTQ7Es"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cars_monthly_dropped = cars_monthly_renamed.drop(columns=['year_month'])\n",
        "cars_monthly_dropped"
      ],
      "metadata": {
        "id": "SQ977tMvRJqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Reordering columns**\n",
        "\n",
        "It feels odd to have the `year` and `month` columns at the end. Let's move them to the front:"
      ],
      "metadata": {
        "id": "oaUMpiICXgzr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns_ordered = ['year', 'month', 'make', 'fuel_type', 'vehicle_type', 'number']\n",
        "cars_monthly_reordered = cars_monthly_dropped.reindex(columns=columns_ordered)\n",
        "cars_monthly_reordered"
      ],
      "metadata": {
        "id": "B0p61THUX0gG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Converting data types**\n",
        "\n",
        "Notice the `number` column is of type `float64`:"
      ],
      "metadata": {
        "id": "42bxi-jARytn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cars_monthly_reordered.dtypes"
      ],
      "metadata": {
        "id": "EGZ_fyTATEd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Theoretically the numbers of car registration in a month should be integers. Let's double check just to be sure:"
      ],
      "metadata": {
        "id": "nPGF22EsTO8r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cars_monthly_reordered.number.map(float.is_integer).all()"
      ],
      "metadata": {
        "id": "IQPzykJGTclT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's convert the `number`, `year`, `month` columns' types to be integer:"
      ],
      "metadata": {
        "id": "TkGTRlngTqH2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cars_monthly_converted = cars_monthly_reordered.astype({\n",
        "    'number': 'int', 'year': 'int', 'month': 'int'})\n",
        "cars_monthly_converted.dtypes"
      ],
      "metadata": {
        "id": "GNSLCknHTvXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will leave the rest of the columns as-is. It's tempting to convert them to `string` type but `string` type requires specifying max length, so we will keep them as `object` since it allows for variable length among column values."
      ],
      "metadata": {
        "id": "2xVyXVYRVq5a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Sorting by values**\n",
        "\n",
        "We can sort by the values of any column(s). To sort by the number of registrations in descending order:"
      ],
      "metadata": {
        "id": "yLwqx7vRZL2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cars_monthly_sorted = cars_monthly_converted.sort_values(\n",
        "    ['number', 'year', 'month'],\n",
        "    ascending=[False, True, True]\n",
        ")\n",
        "cars_monthly_sorted"
      ],
      "metadata": {
        "id": "rX1lrH1wZ3jm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice the index of each row moved with the sorting operation. If we don't care for the original row index, we can invoke `reset_index` to re-establish the index sequence using the sorted values:"
      ],
      "metadata": {
        "id": "Vij7SRCJklfv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cars_monthly_sorted = cars_monthly_sorted.reset_index(drop=True)\n",
        "cars_monthly_sorted"
      ],
      "metadata": {
        "id": "McAc8_gQlA2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alternatively, the above can be achieved using the `ignore_index=True` argument when sorting:"
      ],
      "metadata": {
        "id": "UWaulUDkqU73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cars_monthly_converted.sort_values(\n",
        "    ['number', 'year', 'month'],\n",
        "    ascending=[False, True, True],\n",
        "    ignore_index=True\n",
        ")"
      ],
      "metadata": {
        "id": "SbGDx1ZSqoZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sorting a DataFrame by value could be helpful in discovering possible data integrity issues. For example, we notice here there are entries with `number=0` which we can remove from the dataset:"
      ],
      "metadata": {
        "id": "kUeoLgAJapDG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cars_monthly_nonzero = cars_monthly_sorted[cars_monthly_sorted.number > 0]\n",
        "cars_monthly_nonzero"
      ],
      "metadata": {
        "id": "Cg848POfa4Y1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also pick out the smallest/largest rows for similar data integrity checks:"
      ],
      "metadata": {
        "id": "RZzGLbNEbWp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cars_monthly_nonzero.month.nsmallest(3)"
      ],
      "metadata": {
        "id": "dv3Q5_OxcTs0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cars_monthly_nonzero.month.nlargest(3)"
      ],
      "metadata": {
        "id": "0VXmIUQZbnJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3.2. Aggregation & Grouping\n",
        "\n",
        "In this section, we will explore using pivot tables, crosstabs, and group by operations to aggregate the data."
      ],
      "metadata": {
        "id": "Ftt2PUnRdJyo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **`pivot_table`**\n",
        "\n",
        "To get the aggregated number of new car registrations by make and year, using `pivot_table`:"
      ],
      "metadata": {
        "id": "h0s-xsxDaEqm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cars_monthly_pivoted = cars_monthly_nonzero.pivot_table(index='make', columns='year', values='number', aggfunc='sum')\n",
        "cars_monthly_pivoted"
      ],
      "metadata": {
        "id": "CaLAOLbge4nu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note the resulting DataFrame `cars_monthly_pivoted` has make as its row index, and year its column names."
      ],
      "metadata": {
        "id": "l6PbKq_6l2HZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **`crosstab`**\n",
        "\n",
        "The Same can be achieve with the `pd.crosstab` function, but with different arguments:"
      ],
      "metadata": {
        "id": "BPSUBCecsoTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.crosstab(index=cars_monthly_nonzero.make,\n",
        "            columns=cars_monthly_nonzero.year,\n",
        "            values=cars_monthly_nonzero.number,\n",
        "            aggfunc='sum')"
      ],
      "metadata": {
        "id": "f6-tOFJgf77T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that `crosstab` does not require your data to be in a `DataFrame`, so you might find it natural to use `pivot_table` when your data is already in a `DataFrame` and `crosstab` otherwise. Internally to Pandas, `crosstab` invokes `pivot_table` to calculate the results."
      ],
      "metadata": {
        "id": "Wl24iCtUL6R2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **`groupby`**\n",
        "\n",
        "Those coming from SQL land might feel more comfortable with `groupby`, which requires a reshaping with `unstack` to get the same results:"
      ],
      "metadata": {
        "id": "Y6CHtN-9uVYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cars_monthly_nonzero.groupby(['make', 'year']).sum()[['number']].unstack()"
      ],
      "metadata": {
        "id": "0isucp-Ws2m8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Internally, Pandas uses `groupby` to implement `pivot_table`."
      ],
      "metadata": {
        "id": "O2_lRg7FNtvW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Why do I need to know how things are implemented within Pandas?**\n",
        "\n",
        "Usually the function (e.g. `groupby`) used for implementing other functions (e.g. `pivot_table`, `crosstab`) can be more powerful and flexible as it is considered a more fundamental operation, but it may not be as user-friendly e.g. more parameters may need to be specified or additional operations required to achieve the same thing. It is not necessary to understand the internals of Pandas to use it, but it could help us navigate which might be the most suitable function to use for a given problem."
      ],
      "metadata": {
        "id": "SKDT04c1OgFG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3.3. Reshaping data\n",
        "\n",
        "\"A dataset can be written in two different formats: wide and long. A **wide** format contains values that do not repeat in the first column. A **long** format contains values that do repeat in the first column. Notice that in the wide dataset, each value in the first column is unique.\"\n",
        "\n",
        "<img src=\"https://www.statology.org/wp-content/uploads/2021/12/wideLong1-1.png\"/>\n",
        "\n",
        "Image credit: https://www.statology.org/long-vs-wide-data/\n",
        "\n",
        "Applied researchers often collect, store and analyze their data in the wide format. Classic ANOVA and MANOVA techniques for repeated measures and structural equation models for longitudinal data assume the wide format. Modern multilevel techniques and statistical graphs, however, sometimes work only from the long format.\n",
        "\n",
        "Now let's find out how we can convert between these two formats in Pandas."
      ],
      "metadata": {
        "id": "t8psMFVvTalG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Melting (wide to long)**\n",
        "\n",
        "The `DataFrame` generated from aggregating above is an example of wide format data. Let's convert it to long:"
      ],
      "metadata": {
        "id": "-dakPHT2V6J4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cars_monthly_melted = cars_monthly_pivoted.melt(var_name='year', value_name='number', ignore_index=False)\n",
        "cars_monthly_melted"
      ],
      "metadata": {
        "id": "7kRPgQxMSSaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Pivoting (long to wide)**\n",
        "\n",
        "We can use `pivot` to convert the long format back to wide format:"
      ],
      "metadata": {
        "id": "Yvr-CwDLXVLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cars_monthly_melted.pivot(columns='year')"
      ],
      "metadata": {
        "id": "3DMnMdPiXh9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Transposing**\n",
        "\n",
        "Sometimes we might simply need to flip the rows and columns:"
      ],
      "metadata": {
        "id": "hDteTwuTalq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cars_monthly_pivoted.T"
      ],
      "metadata": {
        "id": "Gncb3jQia50u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3.4. Merging data\n",
        "\n",
        "When working with multiple datasets a common operation is to merge them using a common identifier. Pandas provides the `merge` function to achieve this. For those familiar with relational database, it is very similar to the SQL `JOIN` statement."
      ],
      "metadata": {
        "id": "uS45wPwEeT5b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Preparing for merge**\n",
        "\n",
        "To demonstrate the power of `merge` let's first aggregate the original Singapore annual new car registration dataset at the make and year level, which will allow us to later join with `cars_monthly_melted` and check if the two datasets (anual & monthly) agree on their numbers:"
      ],
      "metadata": {
        "id": "KQm89NTVMdBK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cars_annually_aggregated = singapore_cars_cleaned.pivot_table(index='make', columns='year', values='number', aggfunc='sum')\n",
        "cars_annually_aggregated"
      ],
      "metadata": {
        "id": "PnH9RFs5gCvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A quick check reveals that both the make and year have different unique values between the original annual and monthly datasets:"
      ],
      "metadata": {
        "id": "vsqK18zGjLEv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cars_monthly_pivoted.columns"
      ],
      "metadata": {
        "id": "n_YFEigFiZV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cars_annually_aggregated.index.intersection(cars_monthly_pivoted.index).size"
      ],
      "metadata": {
        "id": "PfyrWDjqhRg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The difference might be attributable to the different time range covered by these two datasets. We can narrow down the join and comparison to only the shared year and make – think inner join for you SQL people."
      ],
      "metadata": {
        "id": "4PDFqxj6jj29"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cars_annually_melted = cars_annually_aggregated.melt(var_name='year', value_name='number', ignore_index=False)\n",
        "cars_annually_melted"
      ],
      "metadata": {
        "id": "79-hQnF_kDeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's drop the `NAN` rows from both melted datasets:"
      ],
      "metadata": {
        "id": "DtInZtERkcL6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cars_annually_melted.dropna(inplace=True)\n",
        "cars_monthly_melted.dropna(inplace=True)\n",
        "print(f'annual dataset shape: {cars_annually_melted.shape}, monthly dataset shape: {cars_monthly_melted.shape}')"
      ],
      "metadata": {
        "id": "NrRiACbnkbkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`reset_index` makes the current index `make` a normal column, and generates a new default index. This will allow us to specify `make` as one of the columns to merge the two DataFrames on later."
      ],
      "metadata": {
        "id": "tfiCr_50pQoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cars_annually_reset = cars_annually_melted.reset_index()\n",
        "cars_monthly_reset = cars_monthly_melted.reset_index()\n",
        "print(f'annual dataset columns: {cars_annually_reset.columns}')\n",
        "print(f'monthly dataset columns: {cars_monthly_reset.columns}')"
      ],
      "metadata": {
        "id": "nCsoVMmHlhO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Performing the merger**\n",
        "\n",
        "With common columns and both datasets in long format, let's perform the merge!"
      ],
      "metadata": {
        "id": "czJUw-6yMnU1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cars_merged = pd.merge(cars_annually_reset, cars_monthly_reset, how=\"inner\", on=[\"make\", \"year\"])\n",
        "cars_merged"
      ],
      "metadata": {
        "id": "i2wpq0U_lHRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Using merge results**\n",
        "\n",
        "`number_x` corresponds to the `number` values from the \"left\" DataFrame `cars_annually_melted`, while `number_y` corresponds to the `number` values from the \"right\" DataFrame `cars_monthly_melted`. We can now compare if the two sets of values are identical for every make-year pair:"
      ],
      "metadata": {
        "id": "K1E5ddVxMzCu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cars_merged.number_x == cars_merged.number_y"
      ],
      "metadata": {
        "id": "dXqdjD5_oQ6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall the NumPy's `all` universal function? Let's use it to check if the two numbers are the same for every row:"
      ],
      "metadata": {
        "id": "stk3whNBqloE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.all(cars_merged.number_x == cars_merged.number_y)"
      ],
      "metadata": {
        "id": "QRmxm9qUowX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Not the case! Use conditional subsetting to see which rows are different:"
      ],
      "metadata": {
        "id": "PIS8Vd2yqzOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cars_merged[cars_merged.number_x != cars_merged.number_y]"
      ],
      "metadata": {
        "id": "_sKxU3wmo1U3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is something we can report to Singapore's Land Transport Authority (LTA). Good job LTA on keeping the vast majority of the records consistent!"
      ],
      "metadata": {
        "id": "3fOw4KW1rAOz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3.6. Exercises: improve merging with index difference and outer join\n",
        "\n",
        "You might have noticed we weren't being very careful with the merger of the annual and monthly data for comparison, because by performing an inner join, only make-year keys present in both datasets will be included for comparison. It's possible that some make-year keys are only present in the annual data, others only present in the monthly data. How can we find out if there are such discrepancies?"
      ],
      "metadata": {
        "id": "AW_jN3cvOCRc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute this code cell to prepare the dataset for exercises below\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# read and clean the monthly dataset\n",
        "cars_monthly = pd.read_csv('https://raw.githubusercontent.com/worldbank/dec-python-course/main/1-foundations/3-numpy-and-pandas/data/Singapore_Monthly_New_Car_Registrations_by_make_type.csv')\n",
        "cars_monthly.dropna(subset=['number'], inplace=True)\n",
        "\n",
        "cars_monthly_renamed = cars_monthly.rename(columns={'month': 'year_month'})\n",
        "cars_monthly_renamed[['year','month']] = cars_monthly_renamed.year_month.str.split(\"-\", expand=True)\n",
        "cars_monthly_dropped = cars_monthly_renamed.drop(columns=['year_month'])\n",
        "\n",
        "columns_ordered = ['year', 'month', 'make', 'fuel_type', 'vehicle_type', 'number']\n",
        "cars_monthly_reordered = cars_monthly_dropped.reindex(columns=columns_ordered)\n",
        "\n",
        "cars_monthly_converted = cars_monthly_reordered.astype({\n",
        "    'number': 'int', 'year': 'int', 'month': 'int'})\n",
        "\n",
        "cars_monthly_nonzero = cars_monthly_converted[cars_monthly_converted.number > 0]\n",
        "cars_monthly_pivoted = cars_monthly_nonzero.pivot_table(index='make', columns='year', values='number', aggfunc='sum')\n",
        "cars_monthly_melted = cars_monthly_pivoted.melt(var_name='year', value_name='number', ignore_index=False)\n",
        "\n",
        "cars_monthly_reset = cars_monthly_melted.dropna().reset_index()\n",
        "\n",
        "# read and clean the annual dataset\n",
        "file_url = 'https://raw.githubusercontent.com/worldbank/dec-python-course/main/1-foundations/3-numpy-and-pandas/data/Singapore_Annual_New_Car_Registrations_by_make_type.csv'\n",
        "singapore_cars = pd.read_csv(file_url)\n",
        "singapore_cars_cleaned = singapore_cars[~np.isnan(singapore_cars.number)]\n",
        "cars_annually_aggregated = singapore_cars_cleaned.pivot_table(index='make', columns='year', values='number', aggfunc='sum')\n",
        "cars_annually_melted = cars_annually_aggregated.melt(var_name='year', value_name='number', ignore_index=False)\n",
        "cars_annually_reset = cars_annually_melted.dropna().reset_index()"
      ],
      "metadata": {
        "id": "RX5xKV5JljEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take a look at the two DataFrames we are going to work with as the starting point:"
      ],
      "metadata": {
        "id": "E0h4IA9iltFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cars_monthly_reset"
      ],
      "metadata": {
        "id": "w_g810WtlnU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cars_annually_reset"
      ],
      "metadata": {
        "id": "JTW8vX9NlsbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 1.\n",
        "\n",
        "Recall the annual dataset `cars_annually_reset` covers year 2015-2021, while the monthly `cars_monthly_reset` covers year 2016-2022, so let's take out 2015 from the annual data (store the result in `cars_annually_16_21`), and filter out 2022 from the monthly (store the result in `cars_monthly_16_21`):"
      ],
      "metadata": {
        "id": "PHE_I69oPOBq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%script echo Remove this line after filling in your own code\n",
        "# hint: use subsetting with boolean indexing\n",
        "# your code here\n",
        "\n",
        "assert 2015 not in cars_annually_16_21.year.to_list()\n",
        "assert 2016 in cars_annually_16_21.year.to_list()\n",
        "assert 2022 not in cars_monthly_16_21.year.to_list()\n",
        "assert 2021 in cars_monthly_16_21.year.to_list()"
      ],
      "metadata": {
        "id": "5J1Cy9v8Rijr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 2.\n",
        "\n",
        "We want to quickly investigate if the make-year keys are different between these two datasets. The function `difference` or `symmetric_difference` on the `Index` object will allow us to carry out the comparison. First let's create such a composite index made of the `make` and `year` column for both `cars_annually_16_21` and `cars_monthly_16_21`. Store the results in `cars_annually_duo_index` and `cars_monthly_duo_index` respectively:"
      ],
      "metadata": {
        "id": "BNIZrEKHgGEO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%script echo Remove this line after filling in your own code\n",
        "# hint: use set_index\n",
        "# your code here\n",
        "\n",
        "assert ('ALFA ROMEO', 2016) in cars_annually_duo_index.index\n",
        "assert ('VOLVO', 2021) in cars_annually_duo_index.index\n",
        "assert ('ALFA ROMEO', 2016) in cars_monthly_duo_index.index\n",
        "assert ('VOLVO', 2021) in cars_monthly_duo_index.index"
      ],
      "metadata": {
        "id": "ZddsxGo6QibW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 3\n",
        "\n",
        "Invoke `difference` twice to compare the indexes of the two DataFrame: `cars_annually_duo_index` and `cars_monthly_duo_index`. First invocation is to find what's in the first index but not in the second; then invoke it again to find what's in the second index but not the first.\n",
        "\n",
        "Alternatively you may invoke `symmetric_difference` once to get the union of all the differences in one go."
      ],
      "metadata": {
        "id": "RyzZvj5FpsWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%script echo Remove this line after filling in your own code\n",
        "# hint: use cars_annually_duo_index.index.difference, or symmetric_difference\n",
        "# Your code here"
      ],
      "metadata": {
        "id": "yjJcSOqTQAzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hint: use cars_monthly_duo_index.index.difference or skip this cell if used symmetric_difference before\n",
        "# Your code here"
      ],
      "metadata": {
        "id": "fbkdZbeGtkNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 4\n",
        "\n",
        "Notice the make Mclaren has two difference spellings. Let's take a look at those records in each dataset by filtering down to just the Mclaren records.\n",
        "\n",
        "You might find the composite index not the most straightforward to work with. Feel free to do the subsetting on `cars_annually_16_21` and `cars_monthly_16_21` instead."
      ],
      "metadata": {
        "id": "c4YbJ_rGqTDw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%script echo Remove this line after filling in your own code\n",
        "# hint: use boolean indexing with .str.casefold() on the make column\n",
        "# Your code here"
      ],
      "metadata": {
        "id": "3EIz2EUfTBpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%script echo Remove this line after filling in your own code\n",
        "# hint: use boolean indexing with .str.casefold() on the make column\n",
        "# Your code here"
      ],
      "metadata": {
        "id": "cr_vBL88TT3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 5.\n",
        "\n",
        "Mclaren is Capitalized in the annual dataset but Mixed-CASE in the monthly dataset. Let's unify them by UPPERCASING all the `make` values. Make the changes inplace for both `cars_annually_16_21` and `cars_monthly_16_21`:"
      ],
      "metadata": {
        "id": "1XwqPgQnv-74"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%script echo Remove this line after filling in your own code\n",
        "# hint: use column creation, but overwrite the 'make' column; check out .str.upper() function\n",
        "# Your code here\n",
        "\n",
        "assert(np.all(cars_annually_16_21['make'].str.isupper()))\n",
        "assert(np.all(cars_monthly_16_21['make'].str.isupper()))"
      ],
      "metadata": {
        "id": "LOAb6VLhT3Oi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 6.\n",
        "\n",
        "Notice there are two entries with different numbers for MCLAREN 2017 in the monthly dataset, which we will need to fix by aggregating. Store the fixed monthly DataFrame in variable `cars_monthly_16_21_cleaned`, which should look like `cars_monthly_16_21` structurally (i.e. no composite/multi index), just with fewer rows:"
      ],
      "metadata": {
        "id": "HnEpLaStzsYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%script echo Remove this line after filling in your own code\n",
        "# hint: use groupby followed by reset_index or\n",
        "# pivot_table followed by melt, dropna, and reset_index\n",
        "\n",
        "# Your code here\n",
        "\n",
        "condition = (cars_monthly_16_21_cleaned.make == 'MCLAREN') & (cars_monthly_16_21_cleaned.year == 2017)\n",
        "assert cars_monthly_16_21_cleaned[condition]['number'].values[0] == 10\n",
        "assert cars_monthly_16_21_cleaned.shape == (316, 3)"
      ],
      "metadata": {
        "id": "NvWXBRRk1D0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 7.\n",
        "\n",
        "With our data re-cleaned, now let's merge `cars_monthly_16_21_cleaned` and `cars_annually_16_21` using the `make` and `year` as keys. Let's perform an outer join this time. Store the merged results in variable `cars_merged_clean`:"
      ],
      "metadata": {
        "id": "xMNqSy7z6E66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%script echo Remove this line after filling in your own code\n",
        "# hint: use pd.merge with arguments how=\"outer\"\n",
        "\n",
        "# Your code here\n",
        "\n",
        "assert cars_merged_clean.shape == (316, 4), \"cars_merged_clean should have 4 columns: year, make, number_x, number_y\""
      ],
      "metadata": {
        "id": "7mnZiWxWc7ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 8.\n",
        "\n",
        "Last but not least, compare the merged numbers for each make-year record. Are they all matching perfectly now?"
      ],
      "metadata": {
        "id": "riaTCqY368Ry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%script echo Remove this line after filling in your own code\n",
        "# hint: use np.all\n",
        "\n",
        "# Your code here"
      ],
      "metadata": {
        "id": "socvPfi_dVQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you've made it this far and still want to learn more, head over to the [bonus material](https://colab.research.google.com/github/worldbank/dec-python-course/blob/main/1-foundations/3-numpy-and-pandas/foundations-s3-bonus.ipynb) for more on libraries, numpy, and pandas!"
      ],
      "metadata": {
        "id": "N8ik_Hx3h4Uj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References & Additional Resources\n",
        "\n",
        "* **Important**: [Pandas Cheat sheet](https://github.com/pandas-dev/pandas/blob/main/doc/cheatsheet/Pandas_Cheat_Sheet.pdf) by Pandas\n",
        "\n",
        "* [Bash Commands for Data Scientists](https://builtin.com/data-science/bash-commands) by Giorgos Myrianthous\n",
        "\n",
        "* [NumPy Quickstart](https://numpy.org/doc/stable/user/quickstart.html) by NumPy\n",
        "\n",
        "* The Pandas section of this workshop is heavily based on [Pandas Workshop](https://github.com/stefmolin/pandas-workshop) by Stefanie Molin\n",
        "\n",
        "* [10 Minutes to Pandas](https://pandas.pydata.org/docs/user_guide/10min.html) - a part of Pandas' official user guide\n",
        "\n",
        "* [Python for Data Science](https://github.com/worldbank/Python-for-Data-Science/tree/master/June_2021_ETEC/day_2) for World Bank ETEC staff\n",
        "\n",
        "* [Python Training for Stata Users](https://github.com/worldbank/dime-python-training) by World Bank Development Impact Evaluation (DIME)\n",
        "\n",
        "* The Singapore annual and monthly car registration datasets used in the Pandas section come from [Singapore Land Transport Authority's Data Mall](https://datamall.lta.gov.sg/content/datamall/en/static-data.html)\n",
        "\n",
        "* [Long vs. Wide Data: What’s the Difference?](https://www.statology.org/long-vs-wide-data/) by Zach from Statology\n",
        "\n",
        "* [Flexible Imputation of Missing Data](https://stefvanbuuren.name/fimd/) by S. van Buuren"
      ],
      "metadata": {
        "id": "VjTKXK_Eb4Jr"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "name": "foundations-s3.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}